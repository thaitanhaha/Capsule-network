{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b412b279",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-09-05T22:36:24.027227Z",
     "iopub.status.busy": "2025-09-05T22:36:24.026898Z",
     "iopub.status.idle": "2025-09-05T22:36:35.250950Z",
     "shell.execute_reply": "2025-09-05T22:36:35.250194Z"
    },
    "papermill": {
     "duration": 11.229663,
     "end_time": "2025-09-05T22:36:35.252501",
     "exception": false,
     "start_time": "2025-09-05T22:36:24.022838",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import Subset\n",
    "from torch.utils.data import DataLoader\n",
    "from collections import Counter\n",
    "from torch.optim import Adam\n",
    "from torchvision import datasets, transforms\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8a396b7",
   "metadata": {
    "papermill": {
     "duration": 0.002533,
     "end_time": "2025-09-05T22:36:35.258304",
     "exception": false,
     "start_time": "2025-09-05T22:36:35.255771",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "62c70a18",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-05T22:36:35.264464Z",
     "iopub.status.busy": "2025-09-05T22:36:35.264133Z",
     "iopub.status.idle": "2025-09-05T22:36:35.381369Z",
     "shell.execute_reply": "2025-09-05T22:36:35.380682Z"
    },
    "papermill": {
     "duration": 0.121703,
     "end_time": "2025-09-05T22:36:35.382633",
     "exception": false,
     "start_time": "2025-09-05T22:36:35.260930",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of files in human_faces_dir: 7219\n",
      "Number of files in flowers_dir: 924\n"
     ]
    }
   ],
   "source": [
    "human_faces_dir = '/kaggle/input/human-faces/Humans'\n",
    "flowers_dir = '/kaggle/input/flowers-dataset/test'\n",
    "\n",
    "human_faces_files = len(os.listdir(human_faces_dir))\n",
    "flowers_files = len(os.listdir(flowers_dir))\n",
    "\n",
    "print(f\"Number of files in human_faces_dir: {human_faces_files}\")\n",
    "print(f\"Number of files in flowers_dir: {flowers_files}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e37aaed7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-05T22:36:35.388910Z",
     "iopub.status.busy": "2025-09-05T22:36:35.388707Z",
     "iopub.status.idle": "2025-09-05T22:36:35.482649Z",
     "shell.execute_reply": "2025-09-05T22:36:35.481957Z"
    },
    "papermill": {
     "duration": 0.09864,
     "end_time": "2025-09-05T22:36:35.484107",
     "exception": false,
     "start_time": "2025-09-05T22:36:35.385467",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "my_transform = transforms.Compose([\n",
    "    transforms.Resize((128, 128)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, human_faces_dir, flowers_dir, transform=None):\n",
    "        self.human_faces_dir = human_faces_dir\n",
    "        self.flowers_dir = flowers_dir\n",
    "        \n",
    "        human_faces_images = [os.path.join(human_faces_dir, fname) for fname in os.listdir(human_faces_dir)]\n",
    "        self.human_faces_images = random.sample(human_faces_images, 300)\n",
    "        flowers_images = [os.path.join(flowers_dir, fname) for fname in os.listdir(flowers_dir)]\n",
    "        self.flowers_images = random.sample(flowers_images, 200)\n",
    "        \n",
    "        self.all_images = self.human_faces_images + self.flowers_images\n",
    "        self.labels = [1] * len(self.human_faces_images) + [0] * len(self.flowers_images)\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.all_images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.all_images[idx]\n",
    "        image = Image.open(img_path).convert(\"RGB\")\n",
    "        \n",
    "        label = self.labels[idx]\n",
    "        \n",
    "        if self.transform: image = self.transform(image)\n",
    "        return image, label\n",
    "\n",
    "dataset = CustomDataset(human_faces_dir, flowers_dir, transform=my_transform)\n",
    "dataloader = DataLoader(dataset, batch_size=128, shuffle=True)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "28604c4d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-05T22:36:35.490584Z",
     "iopub.status.busy": "2025-09-05T22:36:35.490333Z",
     "iopub.status.idle": "2025-09-05T22:36:40.450498Z",
     "shell.execute_reply": "2025-09-05T22:36:40.449692Z"
    },
    "papermill": {
     "duration": 4.964917,
     "end_time": "2025-09-05T22:36:40.452028",
     "exception": false,
     "start_time": "2025-09-05T22:36:35.487111",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 3, 128, 128])\n",
      "tensor([1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0,\n",
      "        0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1,\n",
      "        0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1,\n",
      "        0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1,\n",
      "        1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0,\n",
      "        1, 0, 1, 1, 1, 1, 0, 1])\n"
     ]
    }
   ],
   "source": [
    "for images, labels in dataloader:\n",
    "    print(images.shape)\n",
    "    print(labels)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ddcf0b41",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-05T22:36:40.459396Z",
     "iopub.status.busy": "2025-09-05T22:36:40.459127Z",
     "iopub.status.idle": "2025-09-05T22:36:40.570196Z",
     "shell.execute_reply": "2025-09-05T22:36:40.569487Z"
    },
    "papermill": {
     "duration": 0.116152,
     "end_time": "2025-09-05T22:36:40.571577",
     "exception": false,
     "start_time": "2025-09-05T22:36:40.455425",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class TestDataset(Dataset):\n",
    "    def __init__(self, test_dir, transform=None):\n",
    "        self.test_dir = test_dir\n",
    "        test_images = [os.path.join(test_dir, fname) for fname in os.listdir(test_dir) if fname.endswith(('.jpg', '.png', '.jpeg'))]\n",
    "        test_images = random.sample(test_images, 128)\n",
    "        self.all_images = test_images\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.all_images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.all_images[idx]\n",
    "        image = Image.open(img_path).convert(\"RGB\")\n",
    "        \n",
    "        if self.transform: image = self.transform(image)\n",
    "        return image\n",
    "\n",
    "test_dir = \"/kaggle/input/face-dataset/human-swap/\"\n",
    "test_dataset = TestDataset(test_dir, transform=my_transform)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=128, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "60bb9852",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-05T22:36:40.578168Z",
     "iopub.status.busy": "2025-09-05T22:36:40.577945Z",
     "iopub.status.idle": "2025-09-05T22:36:44.454418Z",
     "shell.execute_reply": "2025-09-05T22:36:44.453297Z"
    },
    "papermill": {
     "duration": 3.881264,
     "end_time": "2025-09-05T22:36:44.455898",
     "exception": false,
     "start_time": "2025-09-05T22:36:40.574634",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 3, 128, 128])\n"
     ]
    }
   ],
   "source": [
    "for images in test_dataloader:\n",
    "    print(images.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bd4fbf2",
   "metadata": {
    "papermill": {
     "duration": 0.003459,
     "end_time": "2025-09-05T22:36:44.463156",
     "exception": false,
     "start_time": "2025-09-05T22:36:44.459697",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Capsule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "67fe9b6a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-05T22:36:44.470061Z",
     "iopub.status.busy": "2025-09-05T22:36:44.469787Z",
     "iopub.status.idle": "2025-09-05T22:36:44.486281Z",
     "shell.execute_reply": "2025-09-05T22:36:44.485375Z"
    },
    "papermill": {
     "duration": 0.021441,
     "end_time": "2025-09-05T22:36:44.487483",
     "exception": false,
     "start_time": "2025-09-05T22:36:44.466042",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def debug_print(debug, message, tensor=None):\n",
    "    if debug:\n",
    "        if tensor is not None:\n",
    "            print(f\"{message}: {tensor.shape}\")\n",
    "        else:\n",
    "            print(message)\n",
    "\n",
    "def squash(input_tensor, epsilon=1e-7):\n",
    "    squared_norm = (input_tensor ** 2 + epsilon).sum(-1, keepdim=True)\n",
    "    output_tensor = (squared_norm / (1. + squared_norm)) *  (input_tensor / torch.sqrt(squared_norm))\n",
    "    return output_tensor\n",
    "\n",
    "class ConvLayer(nn.Module):\n",
    "    def __init__(self, in_channels=3, out_channels=256, kernel_size=9, debug=False):\n",
    "        super(ConvLayer, self).__init__()\n",
    "        self.conv = nn.Conv2d(in_channels=in_channels, out_channels=out_channels, kernel_size=kernel_size, stride=1)\n",
    "        self.debug = debug\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        debug_print(self.debug, \"x after conv\", x)\n",
    "        x = F.relu(x)\n",
    "        debug_print(self.debug, \"x after ReLU\", x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class PrimaryCaps(nn.Module):\n",
    "    def __init__(self, num_capsules=8, in_channels=256, out_channels=32, kernel_size=9, debug=False):\n",
    "        super(PrimaryCaps, self).__init__()\n",
    "        self.capsules = nn.ModuleList()\n",
    "        for _ in range(num_capsules):\n",
    "            capsule = nn.Sequential(\n",
    "                nn.Conv2d(in_channels=in_channels, out_channels=128, kernel_size=9, stride=2, padding=0),\n",
    "                nn.Conv2d(in_channels=128, out_channels=64, kernel_size=9, stride=2, padding=0),\n",
    "                nn.Conv2d(in_channels=64, out_channels=out_channels, kernel_size=9, stride=3, padding=0)\n",
    "            )\n",
    "            self.capsules.append(capsule)\n",
    "        self.debug = debug\n",
    "    \n",
    "    def forward(self, x):\n",
    "        stacked_capsules = [capsule(x) for capsule in self.capsules]\n",
    "        if self.debug: \n",
    "            print(\"capsule_out:\")\n",
    "            for capsule_out in stacked_capsules:\n",
    "                print(\"\\t\", capsule_out.shape)\n",
    "        stacked_capsules = torch.stack(stacked_capsules, dim=1)\n",
    "        debug_print(self.debug, \"stacked_capsules\", stacked_capsules)\n",
    "        flattened_capsules = stacked_capsules.view(x.size(0), 32 * 6 * 6, -1)\n",
    "        debug_print(self.debug, \"flattened_capsules\", flattened_capsules)\n",
    "        squashed_output = squash(flattened_capsules)\n",
    "        debug_print(self.debug, \"squashed_output\", squashed_output)\n",
    "        return squashed_output\n",
    "\n",
    "\n",
    "class DigitCaps(nn.Module):\n",
    "    def __init__(self, num_capsules=2, num_routes=32 * 6 * 6, in_channels=8, out_channels=16, debug=False):\n",
    "        super(DigitCaps, self).__init__()\n",
    "        self.in_channels = in_channels\n",
    "        self.num_routes = num_routes\n",
    "        self.num_capsules = num_capsules\n",
    "        self.W = nn.Parameter(torch.randn(1, num_routes, num_capsules, out_channels, in_channels))\n",
    "        self.debug = debug\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size = x.size(0)\n",
    "        x = torch.stack([x] * self.num_capsules, dim=2).unsqueeze(4)\n",
    "        debug_print(self.debug, \"x after stacking\", x)\n",
    "\n",
    "        W = torch.cat([self.W] * batch_size, dim=0)\n",
    "        debug_print(self.debug, \"W\", W)\n",
    "        \n",
    "        u_hat = torch.matmul(W, x)\n",
    "        debug_print(self.debug, \"u_hat\", u_hat)\n",
    "\n",
    "        b_ij = Variable(torch.zeros(1, self.num_routes, self.num_capsules, 1))\n",
    "        b_ij = b_ij.to(device)\n",
    "        debug_print(self.debug, \"b_ij\", b_ij)\n",
    "\n",
    "        num_iter = 3\n",
    "        for i in range(num_iter):\n",
    "            if self.debug: print()\n",
    "            c_ij = F.softmax(b_ij, dim=1)\n",
    "            debug_print(self.debug, \"c_ij\", c_ij)\n",
    "            c_ij = torch.cat([c_ij] * batch_size, dim=0).unsqueeze(4)\n",
    "            debug_print(self.debug, \"c_ij after repeat\", c_ij)\n",
    "\n",
    "            s_j = (c_ij * u_hat).sum(dim=1, keepdim=True)\n",
    "            debug_print(self.debug, \"s_j\", s_j)\n",
    "\n",
    "            v_j = squash(s_j)\n",
    "            debug_print(self.debug, \"v_j\", v_j)\n",
    "            \n",
    "            a_ij = torch.matmul(u_hat.transpose(3, 4), torch.cat([v_j] * self.num_routes, dim=1))\n",
    "            debug_print(self.debug, \"a_ij\", a_ij)\n",
    "            b_ij = b_ij + a_ij.squeeze(4).mean(dim=0, keepdim=True)\n",
    "            debug_print(self.debug, \"b_ij updated\", b_ij)\n",
    "\n",
    "        return v_j.squeeze(1)\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, debug=False):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.debug = debug\n",
    "        \n",
    "    def forward(self, x, data):\n",
    "        classes = torch.sqrt((x ** 2).sum(2))\n",
    "        debug_print(self.debug, \"classes before softmax\", classes)\n",
    "        classes = F.softmax(classes, dim=0)\n",
    "        debug_print(self.debug, \"classes after softmax\", classes)\n",
    "        \n",
    "        _, max_length_indices = classes.max(dim=1)\n",
    "        debug_print(self.debug, \"max_length_indices\", max_length_indices)\n",
    "        masked = Variable(torch.sparse.torch.eye(2))\n",
    "        debug_print(self.debug, \"masked\", masked)\n",
    "        masked = masked.to(device)\n",
    "        masked = masked.index_select(dim=0, index=Variable(max_length_indices.squeeze(1).data))\n",
    "        debug_print(self.debug, \"masked after index_select\", masked)\n",
    "        \n",
    "        return masked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aa5f1b11",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-05T22:36:44.493752Z",
     "iopub.status.busy": "2025-09-05T22:36:44.493524Z",
     "iopub.status.idle": "2025-09-05T22:36:44.499822Z",
     "shell.execute_reply": "2025-09-05T22:36:44.498986Z"
    },
    "papermill": {
     "duration": 0.010723,
     "end_time": "2025-09-05T22:36:44.500960",
     "exception": false,
     "start_time": "2025-09-05T22:36:44.490237",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CapsuleNet(nn.Module):\n",
    "    def __init__(self, debug=False):\n",
    "        super(CapsuleNet, self).__init__()\n",
    "        self.conv_layer = ConvLayer(debug=debug)\n",
    "        self.primary_capsules = PrimaryCaps(debug=debug)\n",
    "        self.digit_capsules = DigitCaps(debug=debug)\n",
    "        self.decoder = Decoder(debug=debug)\n",
    "        self.mse_loss = nn.MSELoss()\n",
    "        self.debug = debug\n",
    "        \n",
    "    def forward(self, data):\n",
    "        debug_print(self.debug, f\"Input data\", data)\n",
    "        debug_print(self.debug, \"\\nCONV\")\n",
    "        output = self.conv_layer(data)\n",
    "        debug_print(self.debug, \"\\nPRIMARY\")\n",
    "        output = self.primary_capsules(output)\n",
    "        debug_print(self.debug, \"\\nDIGIT\")\n",
    "        output = self.digit_capsules(output)\n",
    "        debug_print(self.debug, \"\\nDECODER\")\n",
    "        masked = self.decoder(output, data)\n",
    "        debug_print(self.debug, \"\\nOUTPUT\", output)\n",
    "        return output, masked\n",
    "\n",
    "    def loss(self, x, target):\n",
    "        return self.margin_loss(x, target)\n",
    "    \n",
    "    def margin_loss(self, x, labels):\n",
    "        batch_size = x.size(0)\n",
    "        v_k = torch.sqrt((x**2).sum(dim=2, keepdim=True))\n",
    "        left = F.relu(0.9 - v_k).view(batch_size, -1)\n",
    "        right = F.relu(v_k - 0.1).view(batch_size, -1)\n",
    "        loss = labels * left + 0.5 * (1.0 - labels) * right\n",
    "        loss = loss.sum(dim=1).mean()\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0b224959",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-05T22:36:44.507403Z",
     "iopub.status.busy": "2025-09-05T22:36:44.507176Z",
     "iopub.status.idle": "2025-09-05T22:36:52.171908Z",
     "shell.execute_reply": "2025-09-05T22:36:52.171099Z"
    },
    "papermill": {
     "duration": 7.669458,
     "end_time": "2025-09-05T22:36:52.173299",
     "exception": false,
     "start_time": "2025-09-05T22:36:44.503841",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input data: torch.Size([128, 3, 128, 128])\n",
      "\n",
      "CONV\n",
      "x after conv: torch.Size([128, 256, 120, 120])\n",
      "x after ReLU: torch.Size([128, 256, 120, 120])\n",
      "\n",
      "PRIMARY\n",
      "capsule_out:\n",
      "\t torch.Size([128, 32, 6, 6])\n",
      "\t torch.Size([128, 32, 6, 6])\n",
      "\t torch.Size([128, 32, 6, 6])\n",
      "\t torch.Size([128, 32, 6, 6])\n",
      "\t torch.Size([128, 32, 6, 6])\n",
      "\t torch.Size([128, 32, 6, 6])\n",
      "\t torch.Size([128, 32, 6, 6])\n",
      "\t torch.Size([128, 32, 6, 6])\n",
      "stacked_capsules: torch.Size([128, 8, 32, 6, 6])\n",
      "flattened_capsules: torch.Size([128, 1152, 8])\n",
      "squashed_output: torch.Size([128, 1152, 8])\n",
      "\n",
      "DIGIT\n",
      "x after stacking: torch.Size([128, 1152, 2, 8, 1])\n",
      "W: torch.Size([128, 1152, 2, 16, 8])\n",
      "u_hat: torch.Size([128, 1152, 2, 16, 1])\n",
      "b_ij: torch.Size([1, 1152, 2, 1])\n",
      "\n",
      "c_ij: torch.Size([1, 1152, 2, 1])\n",
      "c_ij after repeat: torch.Size([128, 1152, 2, 1, 1])\n",
      "s_j: torch.Size([128, 1, 2, 16, 1])\n",
      "v_j: torch.Size([128, 1, 2, 16, 1])\n",
      "a_ij: torch.Size([128, 1152, 2, 1, 1])\n",
      "b_ij updated: torch.Size([1, 1152, 2, 1])\n",
      "\n",
      "c_ij: torch.Size([1, 1152, 2, 1])\n",
      "c_ij after repeat: torch.Size([128, 1152, 2, 1, 1])\n",
      "s_j: torch.Size([128, 1, 2, 16, 1])\n",
      "v_j: torch.Size([128, 1, 2, 16, 1])\n",
      "a_ij: torch.Size([128, 1152, 2, 1, 1])\n",
      "b_ij updated: torch.Size([1, 1152, 2, 1])\n",
      "\n",
      "c_ij: torch.Size([1, 1152, 2, 1])\n",
      "c_ij after repeat: torch.Size([128, 1152, 2, 1, 1])\n",
      "s_j: torch.Size([128, 1, 2, 16, 1])\n",
      "v_j: torch.Size([128, 1, 2, 16, 1])\n",
      "a_ij: torch.Size([128, 1152, 2, 1, 1])\n",
      "b_ij updated: torch.Size([1, 1152, 2, 1])\n",
      "\n",
      "DECODER\n",
      "classes before softmax: torch.Size([128, 2, 1])\n",
      "classes after softmax: torch.Size([128, 2, 1])\n",
      "max_length_indices: torch.Size([128, 1])\n",
      "masked: torch.Size([2, 2])\n",
      "masked after index_select: torch.Size([128, 2])\n",
      "\n",
      "OUTPUT: torch.Size([128, 2, 16, 1])\n"
     ]
    }
   ],
   "source": [
    "capsule_net = CapsuleNet(debug=True).to(device) \n",
    "data, target = next(iter(dataloader))\n",
    "target = torch.sparse.torch.eye(2).index_select(dim=0, index=target)\n",
    "data, target = Variable(data), Variable(target)\n",
    "data, target = data.to(device), target.to(device)\n",
    "output, masked = capsule_net(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "039a8a9d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-05T22:36:52.180895Z",
     "iopub.status.busy": "2025-09-05T22:36:52.180650Z",
     "iopub.status.idle": "2025-09-05T22:52:55.939026Z",
     "shell.execute_reply": "2025-09-05T22:52:55.937927Z"
    },
    "papermill": {
     "duration": 963.763496,
     "end_time": "2025-09-05T22:52:55.940372",
     "exception": false,
     "start_time": "2025-09-05T22:36:52.176876",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [01:00<00:00, 15.24s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15 - Loss: 0.8718 - Accuracy: 0.6180\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [01:01<00:00, 15.47s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/15 - Loss: 0.7686 - Accuracy: 0.6740\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [01:04<00:00, 16.24s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/15 - Loss: 0.7265 - Accuracy: 0.7080\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [01:04<00:00, 16.20s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/15 - Loss: 0.6987 - Accuracy: 0.7200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [01:04<00:00, 16.18s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/15 - Loss: 0.6711 - Accuracy: 0.7560\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [01:04<00:00, 16.13s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/15 - Loss: 0.6504 - Accuracy: 0.7760\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [01:04<00:00, 16.18s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/15 - Loss: 0.6351 - Accuracy: 0.7880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [01:04<00:00, 16.12s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/15 - Loss: 0.6190 - Accuracy: 0.7860\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [01:04<00:00, 16.14s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/15 - Loss: 0.6047 - Accuracy: 0.7960\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [01:04<00:00, 16.17s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/15 - Loss: 0.5859 - Accuracy: 0.8240\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [01:04<00:00, 16.18s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/15 - Loss: 0.5741 - Accuracy: 0.8400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [01:04<00:00, 16.14s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/15 - Loss: 0.5615 - Accuracy: 0.8740\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [01:04<00:00, 16.08s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/15 - Loss: 0.5510 - Accuracy: 0.8760\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [01:04<00:00, 16.22s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/15 - Loss: 0.5376 - Accuracy: 0.8960\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [01:04<00:00, 16.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/15 - Loss: 0.5246 - Accuracy: 0.8960\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "capsule_net = CapsuleNet().to(device) \n",
    "optimizer = Adam(capsule_net.parameters())\n",
    "\n",
    "n_epochs = 15\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    capsule_net.train()\n",
    "    train_loss = 0\n",
    "    correct_train = 0\n",
    "    total_train = 0\n",
    "    for batch_id, (data, target) in enumerate(tqdm(dataloader)):\n",
    "        target = torch.sparse.torch.eye(2).index_select(dim=0, index=target)\n",
    "        data, target = Variable(data), Variable(target)\n",
    "        data, target = data.to(device), target.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        output, masked = capsule_net(data)\n",
    "        loss = capsule_net.loss(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "\n",
    "        preds = np.argmax(masked.data.cpu().numpy(), axis=1)\n",
    "        targets = np.argmax(target.data.cpu().numpy(), axis=1)\n",
    "        correct_train += np.sum(preds == targets)\n",
    "        total_train += len(targets)\n",
    "    \n",
    "    train_accuracy = correct_train / total_train\n",
    "    avg_train_loss = train_loss / len(dataloader)\n",
    "    print(f\"Epoch {epoch+1}/{n_epochs} - Loss: {avg_train_loss:.4f} - Accuracy: {train_accuracy:.4f}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bbe2279c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-05T22:52:55.958163Z",
     "iopub.status.busy": "2025-09-05T22:52:55.957923Z",
     "iopub.status.idle": "2025-09-05T22:53:00.344576Z",
     "shell.execute_reply": "2025-09-05T22:53:00.343674Z"
    },
    "papermill": {
     "duration": 4.397012,
     "end_time": "2025-09-05T22:53:00.346003",
     "exception": false,
     "start_time": "2025-09-05T22:52:55.948991",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 1 0 1 0 1 1 1 1 0 1 0 1 0 0 1 1 0 0 0 0 0 0 1 1 1 1 0 1 1 1 1 0 0 1\n",
      " 1 1 1 1 1 0 0 1 0 1 0 1 1 1 0 0 0 1 1 1 0 1 1 1 1 0 1 0 1 1 1 1 0 1 1 0 0\n",
      " 0 1 1 1 1 1 1 0 1 1 0 0 1 1 1 0 1 0 0 1 1 1 1 0 0 1 1 1 0 1 1 0 1 1 0 1 1\n",
      " 0 0 1 0 1 1 1 1 1 0 1 0 1 1 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "Loss: 1.1138 - Accuracy: 0.3750\n"
     ]
    }
   ],
   "source": [
    "capsule_net.eval()\n",
    "test_loss = 0\n",
    "correct_test = 0\n",
    "total_test = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data in test_dataloader:\n",
    "        target = torch.sparse.torch.eye(2).index_select(dim=0, index=torch.tensor([0] * 128))\n",
    "        data, target = Variable(data), Variable(target)\n",
    "        data, target = data.to(device), target.to(device)\n",
    "    \n",
    "        output, masked = capsule_net(data)\n",
    "        loss = capsule_net.loss(output, target)\n",
    "    \n",
    "        test_loss += loss.item()\n",
    "    \n",
    "        preds = np.argmax(masked.data.cpu().numpy(), axis=1)\n",
    "        targets = np.argmax(target.data.cpu().numpy(), axis=1)\n",
    "        print(preds)\n",
    "        print(targets)\n",
    "        correct_test += np.sum(preds == targets)\n",
    "        total_test += len(targets)\n",
    "    \n",
    "    test_accuracy = correct_test / total_test\n",
    "    avg_test_loss = test_loss / len(test_dataloader)\n",
    "    print(f\"Loss: {avg_test_loss:.4f} - Accuracy: {test_accuracy:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 885385,
     "sourceId": 1504266,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 1170109,
     "sourceId": 1960165,
     "sourceType": "datasetVersion"
    },
    {
     "sourceId": 227433307,
     "sourceType": "kernelVersion"
    }
   ],
   "dockerImageVersionId": 30918,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 1003.815318,
   "end_time": "2025-09-05T22:53:04.061395",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-09-05T22:36:20.246077",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
