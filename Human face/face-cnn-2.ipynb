{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "47056dab",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-09-05T22:24:51.816018Z",
     "iopub.status.busy": "2025-09-05T22:24:51.815685Z",
     "iopub.status.idle": "2025-09-05T22:25:00.381333Z",
     "shell.execute_reply": "2025-09-05T22:25:00.380597Z"
    },
    "papermill": {
     "duration": 8.571369,
     "end_time": "2025-09-05T22:25:00.382959",
     "exception": false,
     "start_time": "2025-09-05T22:24:51.811590",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import Subset\n",
    "from torch.utils.data import DataLoader\n",
    "from collections import Counter\n",
    "from torch.optim import Adam\n",
    "from torchvision import datasets, transforms\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aff21358",
   "metadata": {
    "papermill": {
     "duration": 0.002275,
     "end_time": "2025-09-05T22:25:00.388335",
     "exception": false,
     "start_time": "2025-09-05T22:25:00.386060",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "efd00a5c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-05T22:25:00.394155Z",
     "iopub.status.busy": "2025-09-05T22:25:00.393765Z",
     "iopub.status.idle": "2025-09-05T22:25:00.545741Z",
     "shell.execute_reply": "2025-09-05T22:25:00.544747Z"
    },
    "papermill": {
     "duration": 0.156457,
     "end_time": "2025-09-05T22:25:00.547203",
     "exception": false,
     "start_time": "2025-09-05T22:25:00.390746",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of files in human_faces_dir: 7219\n",
      "Number of files in flowers_dir: 6676\n"
     ]
    }
   ],
   "source": [
    "human_faces_dir = '/kaggle/input/human-faces/Humans'\n",
    "flowers_dir = '/kaggle/input/face-dataset/human-swap/'\n",
    "\n",
    "human_faces_files = len(os.listdir(human_faces_dir))\n",
    "flowers_files = len(os.listdir(flowers_dir))\n",
    "\n",
    "print(f\"Number of files in human_faces_dir: {human_faces_files}\")\n",
    "print(f\"Number of files in flowers_dir: {flowers_files}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "97a36d69",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-05T22:25:00.553299Z",
     "iopub.status.busy": "2025-09-05T22:25:00.553034Z",
     "iopub.status.idle": "2025-09-05T22:25:00.652877Z",
     "shell.execute_reply": "2025-09-05T22:25:00.651935Z"
    },
    "papermill": {
     "duration": 0.104497,
     "end_time": "2025-09-05T22:25:00.654460",
     "exception": false,
     "start_time": "2025-09-05T22:25:00.549963",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "my_transform = transforms.Compose([\n",
    "    transforms.Resize((128, 128)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, human_faces_dir, flowers_dir, transform=None):\n",
    "        self.human_faces_dir = human_faces_dir\n",
    "        self.flowers_dir = flowers_dir\n",
    "        \n",
    "        human_faces_images = [os.path.join(human_faces_dir, fname) for fname in os.listdir(human_faces_dir)]\n",
    "        self.human_faces_images = random.sample(human_faces_images, 300)\n",
    "        flowers_images = [os.path.join(flowers_dir, fname) for fname in os.listdir(flowers_dir)]\n",
    "        self.flowers_images = random.sample(flowers_images, 200)\n",
    "        \n",
    "        self.all_images = self.human_faces_images + self.flowers_images\n",
    "        self.labels = [1] * len(self.human_faces_images) + [0] * len(self.flowers_images)\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.all_images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.all_images[idx]\n",
    "        image = Image.open(img_path).convert(\"RGB\")\n",
    "        \n",
    "        label = self.labels[idx]\n",
    "        \n",
    "        if self.transform: image = self.transform(image)\n",
    "        return image, label\n",
    "\n",
    "dataset = CustomDataset(human_faces_dir, flowers_dir, transform=my_transform)\n",
    "dataloader = DataLoader(dataset, batch_size=128, shuffle=True)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "70cd9fee",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-05T22:25:00.660691Z",
     "iopub.status.busy": "2025-09-05T22:25:00.660443Z",
     "iopub.status.idle": "2025-09-05T22:25:06.051085Z",
     "shell.execute_reply": "2025-09-05T22:25:06.049972Z"
    },
    "papermill": {
     "duration": 5.395103,
     "end_time": "2025-09-05T22:25:06.052481",
     "exception": false,
     "start_time": "2025-09-05T22:25:00.657378",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 3, 128, 128])\n",
      "tensor([1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0,\n",
      "        1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1,\n",
      "        1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1,\n",
      "        1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1,\n",
      "        1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1,\n",
      "        1, 1, 0, 0, 1, 1, 1, 1])\n"
     ]
    }
   ],
   "source": [
    "for images, labels in dataloader:\n",
    "    print(images.shape)\n",
    "    print(labels)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a90207a2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-05T22:25:06.059127Z",
     "iopub.status.busy": "2025-09-05T22:25:06.058842Z",
     "iopub.status.idle": "2025-09-05T22:25:06.072894Z",
     "shell.execute_reply": "2025-09-05T22:25:06.072293Z"
    },
    "papermill": {
     "duration": 0.018788,
     "end_time": "2025-09-05T22:25:06.074197",
     "exception": false,
     "start_time": "2025-09-05T22:25:06.055409",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class TestDataset(Dataset):\n",
    "    def __init__(self, test_dir, transform=None):\n",
    "        self.test_dir = test_dir\n",
    "        test_images = [os.path.join(test_dir, fname) for fname in os.listdir(test_dir) if fname.endswith(('.jpg', '.png', '.jpeg'))]\n",
    "        test_images = random.sample(test_images, 128)\n",
    "        self.all_images = test_images\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.all_images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.all_images[idx]\n",
    "        image = Image.open(img_path).convert(\"RGB\")\n",
    "        \n",
    "        if self.transform: image = self.transform(image)\n",
    "        return image\n",
    "\n",
    "test_dir = \"/kaggle/input/face-dataset/human-swap/\"\n",
    "test_dataset = TestDataset(test_dir, transform=my_transform)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=128, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "da80c346",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-05T22:25:06.080475Z",
     "iopub.status.busy": "2025-09-05T22:25:06.080247Z",
     "iopub.status.idle": "2025-09-05T22:25:11.197820Z",
     "shell.execute_reply": "2025-09-05T22:25:11.196609Z"
    },
    "papermill": {
     "duration": 5.122455,
     "end_time": "2025-09-05T22:25:11.199523",
     "exception": false,
     "start_time": "2025-09-05T22:25:06.077068",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 3, 128, 128])\n"
     ]
    }
   ],
   "source": [
    "for images in test_dataloader:\n",
    "    print(images.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce9e2e2f",
   "metadata": {
    "papermill": {
     "duration": 0.003058,
     "end_time": "2025-09-05T22:25:11.211010",
     "exception": false,
     "start_time": "2025-09-05T22:25:11.207952",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a5134173",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-05T22:25:11.230986Z",
     "iopub.status.busy": "2025-09-05T22:25:11.230682Z",
     "iopub.status.idle": "2025-09-05T22:25:11.238629Z",
     "shell.execute_reply": "2025-09-05T22:25:11.237810Z"
    },
    "papermill": {
     "duration": 0.025923,
     "end_time": "2025-09-05T22:25:11.239976",
     "exception": false,
     "start_time": "2025-09-05T22:25:11.214053",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 256, kernel_size=9, stride=1, padding=4)\n",
    "        self.conv2 = nn.Conv2d(256, 128, kernel_size=9, stride=2, padding=4)\n",
    "        self.conv3 = nn.Conv2d(128, 64, kernel_size=9, stride=2, padding=4)\n",
    "        self.conv4 = nn.Conv2d(64, 32, kernel_size=9, stride=2, padding=4)\n",
    "        self.fc_input_size = self._get_fc_input_size()\n",
    "        self.fc = nn.Linear(self.fc_input_size, 2)\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "    def _get_fc_input_size(self):\n",
    "        dummy_input = torch.zeros(1, 3, 128, 128)\n",
    "        x = self.conv1(dummy_input)\n",
    "        x = F.relu(F.max_pool2d(x, 2))\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = F.relu(F.max_pool2d(x, 2))\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = F.relu(F.max_pool2d(x, 2))\n",
    "        x = F.relu(self.conv4(x))\n",
    "        x = x.view(x.size(0), -1)\n",
    "        return x.size(1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(F.max_pool2d(x, 2))\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = F.relu(F.max_pool2d(x, 2))\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = F.relu(F.max_pool2d(x, 2))\n",
    "        x = F.relu(self.conv4(x))\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "        x = self.softmax(x)\n",
    "        return x\n",
    "\n",
    "    def loss(self, output, target):\n",
    "        return F.cross_entropy(output, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b4303102",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-05T22:25:11.246296Z",
     "iopub.status.busy": "2025-09-05T22:25:11.246093Z",
     "iopub.status.idle": "2025-09-05T22:30:16.519813Z",
     "shell.execute_reply": "2025-09-05T22:30:16.518803Z"
    },
    "papermill": {
     "duration": 305.278823,
     "end_time": "2025-09-05T22:30:16.521460",
     "exception": false,
     "start_time": "2025-09-05T22:25:11.242637",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/4 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/PIL/Image.py:1054: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n",
      "100%|██████████| 4/4 [00:19<00:00,  4.78s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20 - Loss: 0.6936 - Accuracy: 0.6000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:14<00:00,  3.71s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/20 - Loss: 0.6778 - Accuracy: 0.6000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:14<00:00,  3.68s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/20 - Loss: 0.6739 - Accuracy: 0.6000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:14<00:00,  3.66s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/20 - Loss: 0.6749 - Accuracy: 0.6000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:14<00:00,  3.73s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/20 - Loss: 0.6603 - Accuracy: 0.5980\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:14<00:00,  3.68s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/20 - Loss: 0.6368 - Accuracy: 0.6300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:14<00:00,  3.67s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/20 - Loss: 0.6126 - Accuracy: 0.6700\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:15<00:00,  3.81s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/20 - Loss: 0.5797 - Accuracy: 0.7200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:14<00:00,  3.73s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/20 - Loss: 0.5724 - Accuracy: 0.7160\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:15<00:00,  3.79s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/20 - Loss: 0.5063 - Accuracy: 0.8100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:15<00:00,  3.78s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/20 - Loss: 0.4748 - Accuracy: 0.8400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:15<00:00,  3.79s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/20 - Loss: 0.4350 - Accuracy: 0.8860\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:15<00:00,  3.75s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/20 - Loss: 0.4106 - Accuracy: 0.9060\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:15<00:00,  3.84s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/20 - Loss: 0.3975 - Accuracy: 0.9160\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:15<00:00,  3.78s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/20 - Loss: 0.3831 - Accuracy: 0.9340\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:14<00:00,  3.74s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/20 - Loss: 0.3523 - Accuracy: 0.9700\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:14<00:00,  3.75s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/20 - Loss: 0.3394 - Accuracy: 0.9800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:15<00:00,  3.86s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/20 - Loss: 0.3404 - Accuracy: 0.9740\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:15<00:00,  3.83s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/20 - Loss: 0.3454 - Accuracy: 0.9720\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:15<00:00,  3.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/20 - Loss: 0.3328 - Accuracy: 0.9800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "cnn = CNN().to(device)\n",
    "optimizer = Adam(cnn.parameters())\n",
    "\n",
    "n_epochs = 20\n",
    "for epoch in range(n_epochs):\n",
    "    cnn.train()\n",
    "    train_loss = 0\n",
    "    correct_train = 0\n",
    "    total_train = 0\n",
    "    for batch_id, (data, target) in enumerate(tqdm(dataloader)):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        output = cnn(data)\n",
    "        loss = cnn.loss(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "\n",
    "        _, preds = torch.max(output, 1)\n",
    "        correct_train += preds.eq(target).sum().item()\n",
    "        total_train += target.size(0)\n",
    "    \n",
    "    train_accuracy = correct_train / total_train\n",
    "    avg_train_loss = train_loss / len(dataloader)\n",
    "    print(f\"Epoch {epoch+1}/{n_epochs} - Loss: {avg_train_loss:.4f} - Accuracy: {train_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "86ac89db",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-05T22:30:16.542469Z",
     "iopub.status.busy": "2025-09-05T22:30:16.542169Z",
     "iopub.status.idle": "2025-09-05T22:30:20.531608Z",
     "shell.execute_reply": "2025-09-05T22:30:20.530623Z"
    },
    "papermill": {
     "duration": 4.001477,
     "end_time": "2025-09-05T22:30:20.533094",
     "exception": false,
     "start_time": "2025-09-05T22:30:16.531617",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6562\n"
     ]
    }
   ],
   "source": [
    "cnn.eval()\n",
    "correct_test = 0\n",
    "total_test = 0\n",
    "\n",
    "for data in test_dataloader:\n",
    "    data = data.to(device)\n",
    "    output = cnn(data)\n",
    "    target = torch.zeros(output.size(0)).float()\n",
    "    target = target.to(device)\n",
    "\n",
    "    _, preds = torch.max(output, 1)\n",
    "    correct_test += preds.eq(target).sum().item()\n",
    "    total_test += target.size(0)\n",
    "\n",
    "test_accuracy = correct_test / total_test\n",
    "print(f\"Accuracy: {test_accuracy:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 885385,
     "sourceId": 1504266,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 1170109,
     "sourceId": 1960165,
     "sourceType": "datasetVersion"
    },
    {
     "sourceId": 227433307,
     "sourceType": "kernelVersion"
    }
   ],
   "dockerImageVersionId": 30918,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 334.043336,
   "end_time": "2025-09-05T22:30:22.944967",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-09-05T22:24:48.901631",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
